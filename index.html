<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>faceRoster</title>
    <script src="js/face-api.js"></script>
</head>

<body>
    <label>Upload Image:</label> <input id="queryImgUploadInput" type="file" onchange="uploadQueryImage(event)" accept=".jpg, .jpeg, .png">
    <div id="imagediv">
        <img id="myImg" src="bbt1.jpg" alt="">
    </div>
    <script>
    const tiny = false;
    console.time();

    function drawFaceRecognitionResults(results) {
    	console.log(results)
        let paras = document.getElementsByClassName('faceNames');
        while (paras[0]) {
            paras[0].parentNode.removeChild(paras[0]);
        }
        results.forEach(function(result) {
            let btn = document.createElement("button");
            btn.innerText = result.detection.classScore.toFixed(2) + ';' + result.landmarks.imageWidth + ' x ' + result.landmarks.imageHeight + ';' + result.expressions.asSortedArray()[0].expression + ' Age:' + result.age.toFixed(0) + ' Gender: ' + result.gender;
            btn.style = 'position:absolute; top:' + result.detection.box.top + 'px;left:' + result.detection.box.left + 'px; zindex:2';
            btn.className = 'faceNames';
            document.getElementById("imagediv").appendChild(btn);
        })
    }

    async function loadModels() {
        if (tiny) {
            await faceapi.nets.tinyFaceDetector.load("weights");
            await faceapi.nets.faceLandmark68TinyNet.load("weights");
        } else {
            await faceapi.nets.ssdMobilenetv1.load("weights");
            await faceapi.nets.faceLandmark68Net.load("weights");
        }
        await faceapi.nets.faceExpressionNet.load("weights");
        await faceapi.nets.ageGenderNet.load("weights");

        console.timeLog();
    }

    async function updateResults() {
        if (tiny) {
            results = await faceapi.detectAllFaces("myImg", new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks(true).withFaceExpressions();
        } else {
            results = await faceapi.detectAllFaces("myImg").withFaceLandmarks().withFaceExpressions().withAgeAndGender();
        }

        drawFaceRecognitionResults(results);

        console.timeEnd();
    }

    async function uploadQueryImage(e) {
    	console.time();
        const imgFile = e.target.files[0]
        const img = await faceapi.bufferToImage(imgFile)
        document.getElementById("myImg").src = img.src
        updateResults()
    }

    loadModels().then(updateResults)
    </script>
</body>

</html>